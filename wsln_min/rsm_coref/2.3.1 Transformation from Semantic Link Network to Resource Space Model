Definition 2.1. For a Semantic Link Network SLN (N, SL), (1) if for some nodes n1, n2 N (SLN), there exists a directed path p(n1, n2) from n1 to n2, then we call n1 can reach n2; (2) if for any pair of nodes n1, n2 N (SLN), n1 can reach n2 or n2 can reach n1, then we call a Semantic Link Network SLN (N, SL) is unilaterally connected; (3) if for any n1, n2 N (SLN), n1 can reach n2 and n2 can reach n1, then a Semantic Link Network SLN (N, SL) is called strongly connected; and (4) let SLN be the underlying undirected graph of a Semantic Link Network SLN (N, SL), then a Semantic Link Network SLN (N, SL) is called weakly connected if SLN is connected; (5) if at least one semantic link (or can be derived from existing links) points from n1 to n2, we say that n2 is semantically reachable from n1, and that n1 and n2 are accessible each other by browsing (regardless of direction). 
The weak connectedness is about the reachability of browsing. If we have n1n2, n2n3  n1n3 (‘’ means by implication), then we say that  or the -link is transitive, and that there exists a semantic chain from n1 to n1n3. Then we can see that the unilateral and strong con-nectness is about the reachability of the semantic links by induction. 
Definition 2.2. A sub-graph SLN of SLN (N, SL) is called a (weak, unilat-eral, strong) connected component of SLN (N, SL) if (1) A sub-graph SLN of SLN (N, SL) is (weakly, unilaterally, strongly) connected; and (2) if A sub-graph SLN of SLN (N, SL) is (weakly, unilaterally, strongly) connected too, and A sub-graph SLN of SLN (N, SL) SLN, then A sub-graph SLN of SLN (N, SL)  SLN, i.e., A sub-graph SLN of SLN (N, SL) is a maximal subset which is (weakly, unilaterally, strongly) con-nected. 
A semantic component can be viewed as a point in the high-level re-source space, then we can get the corresponding high-level resource space from a semantic link network as follows: 
For a Semantic Link Network SLN (N, SL), let a Semantic Link Network SLN (N, SL) ={C1, C2, , Cm}, where Ci represents a strongly connected component of a Semantic Link Network SLN (N, SL) and Ci  Cj = . Then N (a Semantic Link Network SLN (N, SL)) = N(Ci), where N(Ci) denotes the nodes of Ci.  A strongly connected component of a Semantic Link Network SLN (N, SL) stands for a certain semantics that is independent from the semantics of other components. So a Semantic Link Network can be transformed to a Resource Space Model by mapping the strongly connected components into the points in the space. Fig.5 depicts such a transformation. 
A transformation from a Semantic Link Network to a resource space exists because: 
There exists an n-dimensional semantic space RS(X1, X2, , Xn) to rep-resent the semantics of a Semantic Link Network.  The simplest case is a vector (C1, …, Cn). 
For each strongly connected semantic component Ci of the SLN, we can find projections on each axis x1, x2, , xn, representing fine seman-tics on each axis x1, x2, , xn.  Each axis takes the projection of C1, …, Cn on Each axis as coordinates. 
Ci(x1, x2, , xn) corresponds to a point in RS. 
The rest points in RS can be assigned as null points. 
Given a domain ontology, above steps can determine a resource space RS(X1, X2, , Xn) by mapping axis and axis's coordinates onto concepts in the ontology hierarchy. 
For a Semantic Link Network SLN ={C1, C2, C3, C4} shown in Fig.2.4, Ci is the strong component, 1 i 4. Then, we can get the resource space RS(X1, X2)= {p1, p2, p3, p4} (other two unfilled points represent null points). We can see that when the high-level semantics are got in the re-source space, the low-level semantics such as p1 p4, p3 p4, p2 p3, and p2 p1 in the Semantic Link Network are lost. 
Corollary 2.1. A 1NF Semantic Link Network (1NF-SLN) can be trans-formed to a 1NF Resource Space Model (1NF-RSM). 
Proof. If a Semantic Link Network is 1NF, then there do not exist se-mantic-equivalent nodes in a Semantic Link Network. From the definition of the strongly con-nected component, there should not exist the same strongly connected component in a Semantic Link Network. Suppose RS is the high-level resource space, then there should not exist the same sets of points in RS. So, there does not exist name duplication between coordinates at any axis in RS. Then RS is also the 1NF.  
Corollary 2.2. A 2NF Semantic Link Network (2NF-SLN) can be trans-formed to a 2NF Resource Space Model (2NF-RSM). 
Proof. If a Semantic Link Network is 2NF, then there do not exist incon-sistent and duplicate semantic links between the same pair of nodes, is guarantees that the strongly connected components of a Semantic Link Network are correct in semantics. Suppose {C1, C2, , Cm} is the set of strongly connected components of the Semantic Link Network SLN and RS is the high-level resource space, then RS={ p1, p2, , pm}, where p1 corresponds to Ci, 1 i m. If RS is not the second-normal-form, then there exist some points p1 and pj are not independent from each other, i.e., R(Ci)  R(Cj )  , which means Ci  Cj  . This is not consistent with that Ci and R(Cj are different strongly connected components in the Semantic Link Network SLN, so RS is also a 2NF-RSM.  
Corollary 2.3. A 3NF Semantic Link Network (3NF-SLN) can be trans-formed to a 3NF Resource Space Model (3NF-RSM). 
Proof. If a Semantic Link Network SLN is a 3NF, then there does not ex-ist isolated nodes (accessible from each other), therefore all the strongly connected components of a Semantic Link Network SLN are accessible from each other. Suppose RS is the high-level resource space, we can get that any of RS's point are reachable from others, then every axis Xi can represent all the resources in RS, which is equivalent to that any two axes of RS are orthogonal with each other (Zhuge et al., 2005c), so RS is also a 3NF.  
    The above three corollaries show that the normal forms of the Re-source Space Model and the Semantic Link Network have common prop-erties in solving the redundancy and inconsistency. 