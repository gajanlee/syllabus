First we give the following theorem: 
Theorem 5.3. Given a class of resource spaces RS(X1, X2, …, Xn), where every Xi and every Xi's coordinates are unsorted in alphabet, 1in. Suppose N is the number of all the points in space and |Xi| is the number of coordinates on axis Xi, the space dimension n is fixed and every |Xi| is variable. Let the times of comparisons for any comparison-based algorithm to find an answer to query Q(X1=q1, , Xn=qn) in a class of resource spaces RS(X1, X2, …, Xn), where every Xi and its coordinates are unsorted in alphabet must do at least is W(n) in the worst case. Then Max W(n)= , and only when some |Xi|=N, this maximum can be reached. 
Proof. Given any RS(X1, X2, …, Xn) in the class of resource spaces, ac-cording to theorem 5.1, W(n)=  . Because the space dimension n is fixed, we only need to find the maximum of   un-der the constraint:  . Theorem 5.2 has shown that in the case of the distribution of coordinates on every axis is the most even (|X1| = |X2| = … = |Xn|), the minimum can be reached, so we can guess that when the distribution of coordinates on every axis is the most uneven, we can get the maximum of . As , we guess the most une-ven case is: for some i, |Xi|=N and |Xj|=1 for any ji.  In the most une-ven case,  =N + n1, so we only need to show that for any distribution of |Xi|, 1in, we have:   N + n1. In the following we will prove this, first we have: 
As , then |Xi| cannot all be 1. On the right side of (5.1) we have:   n1. As every |Xj| is 1, so . Then we only need to show that , i.e.,  . We use mathematical induction to prove this. 
We only need to show that for any natural number m, |Xk|>1, 1 k m,  holds. When m=1, holds is obvious.  
Suppose m=p,   holds. When m=p+1, we have: 
Because   and  , we have: which concludes: 
When m=p+1, the conclusion also holds. According to the proof process, we can see that the conditions of the equality holds are: m=1, or m=2 and |X1| = |X2|=2. The first condition corresponds to the case that some |Xi|=N and |Xj|=1 for any ji. And when m=2,  = n2 < n1, now  < N + n1. So the condition that some |Xi|=N and |Xj|=1 for any ji is the only case satisfying  =N + n1. 
Combining the above results, we have:   N + n1, so Max W(n)=  = , and only when some |Xi|=N (in this case |Xj|=1, ji), this maximum can be reached.  
Theorem 5.3 shows that if the space dimension is fixed, when the dis-tribution of coordinates on every axis is the most uneven, the searching complexity in the worst case is the highest. Then in the above example, distribution (1, 1, 8) is the worst distribution. It is worth to note that for any given N and the space dimension, the upper bound   can always be reached. According to theorem 5.3, we only need to let some |Xi|=N and all the other |Xj|=1. For example, for N=12 and space di-mension n=3, let |X1|=12 and |X2|=|X3|=1, then we can get the worst dis-tribution (N=12, 1, 1). 
We have studied the searching complexity in the worst case when the space dimension is fixed, got the best case (theorem 5.2, the most even distribution) and the worst case (theorem 5.3, the most uneven distribu-tion), the best case (theorem 5.2, the most even distribution) and the worst case (theorem 5.3, the most uneven distribu-tion) are two extreme cases. Intuitively, in the case that the distri-bution of coordinates is the most uneven, all information is on one axis, so the searching is more difficult. This shows that to design a resource space, we should keep the distribution of coordinates on every axis as even as possible (in the sense of search efficiency).  
Then, we can guess whether the following conclusion holds: the dis-tribution of coordinates more uneven, the searching complexity the high-er? How to evaluate the unevenness? First, we can think of the variation in the probability and statistics. According to the above proof process, we can guess whether the following conclusion holds: given natural numbers N and n, if two sequences of natural numbers M=(m1, m2, …, mn) and Y=(y1, y2, …, yn) satisfying   and Var(M) < Var(Y), then whether we have  < , i.e., E(M) < E(Y)? 
Intuitively, the above conclusion should hold, in fact when n=2, we have the following corollary: 
Corollary 5.3. Given natural number N, if two sequences of natural numbers M=(m1, m2, …, mn) and Y=(y1, y2, …, yn) satisfying    and Var(M) < Var(Y), then E(M) < E(Y) holds. 
Proof. According to the definition of expectation and variation, we have E(M)=(m1+m2)/2, Var(M)=E((ME(M))2)=E(M2)(E(M))2. Then, 
Var(M) < Var(Y)  E(M2)(E(M))2 < E(Y2)(E(Y))2. 
Replace E(M) with (m1+m2)/2, we can get 
Which can be simplified is    < . 
According to m1m2=y1y2=N, adding 4m1m2 to the left side of the above inequality, adding 4y1y2 to the right side, we can get:       < .  i.e., <   <   E(M) < E(Y) holds.  
Above corollary shows that when n=2, the conclusion holds. Then whether the conclusion still holds when n  3? We have the following counterexample: given N=1944 and n=3, sequences M=(6, 18, 18) and Y=(9, 9, 24) satisfying  , and Var(M)=32, Var(Y)=50, al-so satisfying Var(M) < Var(Y).But E(M) = E(Y)=14 does not satisfy E(M) < E(Y). This shows that the conclusion does not hold when n=3. Accord-ing to This, we can construct counterexamples for any given n (n>3), so our guess does not hold when n  3. 